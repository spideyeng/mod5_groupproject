{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Council HR Bot (Denbighshire) \u2014 MVP Clean Notebook\n\nThis notebook builds a **Router + Leave/Travel/Pay RAG agents + Web Scout** using **Groq + Chroma + LangGraph**.\n\n**Run cells from top \u2192 bottom.**\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "!pip -q install -U langchain langchain-core langchain-community langchain-groq langgraph chromadb sentence-transformers pypdf duckduckgo-search gradio\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Download PDFs (Brain)\nThese are the 3 policy PDFs used by the specialist agents.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import os, requests\n\nPDFS = {\n    \"annual_leave_guidance.pdf\": \"https://www.denbighshire.gov.uk/en/documents/hr-policies/my-employment/leave-and-attendance/annual-leave-guidance-for-managers-and-employees-v5-9-1.pdf\",\n    \"travel_and_subsistence.pdf\": \"https://www.denbighshire.gov.uk/en/documents/hr-policies/my-employment/pay-and-benefits/travel-and-subsistence-v-2-2.pdf\",\n    \"pay_policy_2025_2026.pdf\": \"https://www.denbighshire.gov.uk/en/documents/hr-policies/my-employment/pay-and-benefits/pay-policy-2025-2026.pdf\",\n}\n\nout_dir = \"data/pdfs\"\nos.makedirs(out_dir, exist_ok=True)\n\nfor name, url in PDFS.items():\n    path = os.path.join(out_dir, name)\n    r = requests.get(url, timeout=60)\n    r.raise_for_status()\n    with open(path, \"wb\") as f:\n        f.write(r.content)\n    print(\"Downloaded:\", path)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Groq API key + LLM\nPaste your Groq key when prompted.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import os, getpass\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Paste your GROQ API key here: \")\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from langchain_groq import ChatGroq\n\n# Fast model option: llama-3.1-8b-instant (faster)\n# Quality model option: llama-3.3-70b-versatile (better answers, slower)\nMODEL_NAME = \"llama-3.1-8b-instant\"  # change to \"llama-3.3-70b-versatile\" if you want higher quality\n\nllm = ChatGroq(model=MODEL_NAME, temperature=0)\nprint(llm.invoke(\"Reply exactly: GROQ_OK\").content)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Build persistent Vector DBs (Leave / Travel / Pay)\nWe chunk PDFs and store embeddings in Chroma so we don't rebuild every time.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import os\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.vectorstores import Chroma\n\nPERSIST_ROOT = \"chroma_db\"\nos.makedirs(PERSIST_ROOT, exist_ok=True)\n\nemb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\nsplitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n\ndef build_store(pdf_path: str, collection: str, persist_dir: str) -> Chroma:\n    docs = PyPDFLoader(pdf_path).load()\n    fname = os.path.basename(pdf_path)\n    for d in docs:\n        d.metadata[\"source\"] = fname\n    chunks = splitter.split_documents(docs)\n    vs = Chroma.from_documents(\n        documents=chunks,\n        embedding=emb,\n        persist_directory=persist_dir,\n        collection_name=collection,\n    )\n    print(f\"Built {collection}: chunks={len(chunks)} -> {persist_dir}\")\n    return vs\n\nleave_vs  = build_store(\"data/pdfs/annual_leave_guidance.pdf\", \"leave\",  os.path.join(PERSIST_ROOT, \"leave_store\"))\ntravel_vs = build_store(\"data/pdfs/travel_and_subsistence.pdf\", \"travel\", os.path.join(PERSIST_ROOT, \"travel_store\"))\npay_vs    = build_store(\"data/pdfs/pay_policy_2025_2026.pdf\", \"pay\",     os.path.join(PERSIST_ROOT, \"pay_store\"))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Generic RAG helper (returns answer + sources)\nThis prevents hallucinations by grounding answers in retrieved chunks.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\nrag_prompt = ChatPromptTemplate.from_template(\"\"\"\nYou are an HR policy assistant.\nAnswer using ONLY the context.\nIf the answer is not in the context, say: I don't know.\n\nContext:\n{context}\n\nQuestion: {question}\n\nAnswer:\n\"\"\")\n\ndef _get_docs(vs, question: str, k: int = 6):\n    retriever = vs.as_retriever(search_kwargs={\"k\": k})\n    try:\n        return retriever.invoke(question)\n    except Exception:\n        return retriever.get_relevant_documents(question)\n\ndef _format_context(docs):\n    return \"\\n\\n---\\n\\n\".join(\n        f\"[{d.metadata.get('source','doc')} | page {d.metadata.get('page','?')}]\\n{d.page_content}\"\n        for d in docs\n    )\n\ndef ask_rag(vs, question: str) -> str:\n    docs = _get_docs(vs, question, k=6)\n    context = _format_context(docs)\n    chain = rag_prompt | llm | StrOutputParser()\n    answer = chain.invoke({\"context\": context, \"question\": question})\n    # add sources at end\n    cites = []\n    for d in docs:\n        cites.append((d.metadata.get(\"source\",\"doc\"), d.metadata.get(\"page\",\"?\")))\n    # unique\n    uniq = []\n    for c in cites:\n        if c not in uniq:\n            uniq.append(c)\n    src = \"\\n\".join([f\"- {s} (page {p})\" for s,p in uniq]) if uniq else \"- (no sources)\"\n    return answer.strip() + \"\\n\\nSources:\\n\" + src\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Web Scout tool (live website)\nUsed for job vacancies, news, contacts.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from duckduckgo_search import DDGS\n\ndef web_scout(query: str, max_results: int = 3) -> str:\n    q = f\"site:denbighshire.gov.uk {query}\"\n    results = []\n    with DDGS() as ddgs:\n        for r in ddgs.text(q, max_results=max_results):\n            results.append(f\"- {r.get('title','')}\\n  {r.get('href','')}\\n  {r.get('body','')}\")\n    return \"\\n\".join(results) if results else \"No results found.\"\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Router + LangGraph (MVP)\nRoutes to Leave/Travel/Pay policy agents or Web Scout.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from typing import TypedDict\nfrom langgraph.graph import StateGraph, END\n\nclass State(TypedDict):\n    question: str\n    route: str\n    answer: str\n\ndef router_node(state: State) -> State:\n    q = state[\"question\"].lower()\n\n    leave_kw  = [\"annual leave\",\"holiday\",\"holidays\",\"carry over\",\"carryover\",\"sick\",\"sickness\",\"bank holiday\",\"leave year\",\"book leave\"]\n    travel_kw = [\"travel\",\"subsistence\",\"mileage\",\"hire car\",\"hotel\",\"claim\",\"allowance\",\"parking\",\"public transport\"]\n    pay_kw    = [\"pay\",\"salary\",\"grade\",\"honoraria\",\"honorarium\",\"redundancy\",\"overtime\",\"allowance\",\"pay policy\"]\n    web_kw    = [\"job\",\"jobs\",\"vacancy\",\"vacancies\",\"news\",\"contact\",\"email\",\"phone\",\"address\"]\n\n    if any(k in q for k in web_kw):\n        state[\"route\"] = \"web\"\n    elif any(k in q for k in travel_kw):\n        state[\"route\"] = \"travel\"\n    elif any(k in q for k in pay_kw):\n        state[\"route\"] = \"pay\"\n    elif any(k in q for k in leave_kw):\n        state[\"route\"] = \"leave\"\n    else:\n        state[\"route\"] = \"leave\"  # fallback\n    return state\n\ndef leave_node(state: State) -> State:\n    state[\"answer\"] = ask_rag(leave_vs, state[\"question\"])\n    return state\n\ndef travel_node(state: State) -> State:\n    state[\"answer\"] = ask_rag(travel_vs, state[\"question\"])\n    return state\n\ndef pay_node(state: State) -> State:\n    state[\"answer\"] = ask_rag(pay_vs, state[\"question\"])\n    return state\n\ndef web_node(state: State) -> State:\n    state[\"answer\"] = web_scout(state[\"question\"], max_results=3)\n    return state\n\ng = StateGraph(State)\ng.add_node(\"router\", router_node)\ng.add_node(\"leave_agent\", leave_node)\ng.add_node(\"travel_agent\", travel_node)\ng.add_node(\"pay_agent\", pay_node)\ng.add_node(\"web_agent\", web_node)\n\ng.set_entry_point(\"router\")\n\ndef route_to_next(state: State) -> str:\n    return {\n        \"leave\": \"leave_agent\",\n        \"travel\": \"travel_agent\",\n        \"pay\": \"pay_agent\",\n        \"web\": \"web_agent\",\n    }[state[\"route\"]]\n\ng.add_conditional_edges(\"router\", route_to_next, {\n    \"leave_agent\": \"leave_agent\",\n    \"travel_agent\": \"travel_agent\",\n    \"pay_agent\": \"pay_agent\",\n    \"web_agent\": \"web_agent\",\n})\n\ng.add_edge(\"leave_agent\", END)\ng.add_edge(\"travel_agent\", END)\ng.add_edge(\"pay_agent\", END)\ng.add_edge(\"web_agent\", END)\n\napp = g.compile()\nprint(\"\u2705 app ready:\", \"app\" in globals())\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7) Test prompts (assignment self-check)\nRun these and keep the output as evidence for submission.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "tests = [\n    (\"Leave\",  \"How many days of annual leave am I entitled to?\"),\n    (\"Travel\", \"When am I required to use a hire car instead of my own vehicle?\"),\n    (\"Pay\",    \"How are honoraria payments calculated?\"),\n    (\"Web\",    \"Are there any IT jobs available right now?\"),\n]\n\nfor label, q in tests:\n    out = app.invoke({\"question\": q, \"route\": \"\", \"answer\": \"\"})\n    print(\"\\n===\", label, \"===\")\n    print(\"Q:\", q)\n    print(\"Route:\", out[\"route\"])\n    print(out[\"answer\"][:1500])\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8) Simple end-user UI (Gradio)\nThis creates a textbox where users type questions and get answers.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import gradio as gr\n\ndef hr_bot(question: str) -> str:\n    out = app.invoke({\"question\": question, \"route\": \"\", \"answer\": \"\"})\n    return f\"ROUTE: {out['route']}\\n\\n{out['answer']}\"\n\ndemo = gr.Interface(\n    fn=hr_bot,\n    inputs=gr.Textbox(lines=2, placeholder=\"Ask the Council HR Bot...\"),\n    outputs=\"text\",\n    title=\"Council HR Bot (Router + Policy RAG + Web Scout)\",\n    description=\"Ask about Leave / Travel / Pay policies, or jobs/news/contact on denbighshire.gov.uk.\"\n)\n\ndemo.launch(share=True)\n"
    }
  ],
  "metadata": {
    "colab": {
      "name": "Council_HR_Bot_MVP_Clean.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}